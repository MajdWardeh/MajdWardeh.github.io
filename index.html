<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Majd Wardeh | Computer Vision & Robotics</title>
    <meta name="description" content="Computer Vision & Robotics Engineer — Visual SLAM, Autonomous Systems, Embedded ML" />
    <style>
      :root {
        --bg: #ffffff;
        --surface: #ffffff;
        --text: #0f172a;
        --muted: #616a7d;
        --accent: #1a3d7c;
        --accent-soft: #e8efff;
        --border: #e6e8ee;
        --shadow: 0 1px 2px rgba(17, 24, 39, 0.06), 0 8px 24px rgba(17, 24, 39, 0.06);
        --font-sans: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Inter, system-ui, sans-serif;
        --max-width: 960px;
        --radius: 14px;
      }
      * { box-sizing: border-box; }
      html, body { height: 100%; }
      body {
        margin: 0;
        font-family: var(--font-sans);
        color: var(--text);
        background: var(--bg);
        -webkit-font-smoothing: antialiased;
        -moz-osx-font-smoothing: grayscale;
      }
      a { color: var(--accent); text-decoration: none; }
      .wrap { max-width: var(--max-width); margin: 0 auto; padding: 24px 20px 40px; }
      .card { background: var(--surface); border: 1px solid var(--border); border-radius: var(--radius); box-shadow: var(--shadow); }
      .hero { display: grid; grid-template-columns: 1fr auto; gap: 20px; padding: 22px; align-items: center; }
      .hero .left { min-width: 0; }
      .name { font-size: 1.9rem; font-weight: 700; letter-spacing: 0.01em; }
      .tagline { font-size: 0.98rem; color: var(--muted); margin-top: 6px; }
      .meta { margin-top: 10px; font-size: 0.9rem; color: var(--muted); }
      .meta span:not(:last-child)::after { content: "•"; margin: 0 8px; color: #aab0bd; }
      .labels { margin-top: 10px; display: flex; flex-wrap: wrap; gap: 6px; }
      .chip { display: inline-block; font-size: 0.76rem; padding: 6px 10px; border-radius: 999px; border: 1px solid var(--border); background: #fff; color: #3b4353; }
      .photo { width: 96px; height: 96px; border-radius: 12px; background-size: cover; background-position: center; border: 1px solid var(--border); box-shadow: var(--shadow); }
      .nav { position: sticky; top: 0; z-index: 40; backdrop-filter: saturate(180%) blur(10px); background: rgba(255,255,255,0.75); border-bottom: 1px solid var(--border); }
      .nav-inner { max-width: var(--max-width); margin: 0 auto; display: flex; gap: 10px; padding: 10px 20px; overflow-x: auto; }
      .nav a { font-size: 0.86rem; color: #334155; padding: 7px 12px; border-radius: 999px; border: 1px solid transparent; }
      .nav a:hover { background: var(--accent-soft); color: var(--accent); border-color: #ccdafd; }
      main { display: grid; grid-template-columns: 1.75fr 1.1fr; gap: 20px; margin-top: 20px; }
      @media (max-width: 920px) { .hero { grid-template-columns: 1fr; } main { grid-template-columns: 1fr; } .photo { width: 88px; height: 88px; } }
      section { padding: 18px 22px; }
      h2 { font-size: 0.9rem; text-transform: uppercase; letter-spacing: 0.16em; color: var(--accent); margin: 2px 0 8px; }
      p, li { font-size: 0.9rem; color: var(--muted); }
      .block { padding: 12px 0; border-bottom: 1px solid var(--border); }
      .block:last-child { border-bottom: none; }
      .title-line { display: flex; justify-content: space-between; gap: 10px; font-weight: 600; color: #1f2937; }
      .sub { font-size: 0.85rem; color: var(--muted); margin-top: 2px; }
      .pills { margin-top: 8px; display: flex; flex-wrap: wrap; gap: 6px; }
      .pill { font-size: 0.75rem; padding: 4px 10px; border: 1px solid var(--border); border-radius: 999px; color: #465067; }
      .links a { font-size: 0.85rem; margin-right: 10px; }
      ul { padding-left: 18px; margin: 6px 0 0; }
      .note { font-size: 0.86rem; color: var(--muted); }
      .footer { text-align: center; color: var(--muted); font-size: 0.8rem; padding: 18px; }
      html { scroll-behavior: smooth; }
    </style>
    <!-- React (no build step) -->
    <script crossorigin src="https://unpkg.com/react@18/umd/react.production.min.js"></script>
    <script crossorigin src="https://unpkg.com/react-dom@18/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
  </head>
  <body>
    <div class="nav">
      <nav class="nav-inner">
        <a href="#about">About</a>
        <a href="#experience">Experience</a>
        <a href="#projects">Projects</a>
        <a href="#thesis">Thesis</a>
        <a href="#education">Education</a>
        <a href="#awards">Awards</a>
        <a href="#skills">Skills</a>
        <a href="#contact">Contact</a>
      </nav>
    </div>
    <div id="root" class="wrap"></div>

    <script type="text/babel">
      const Chip = ({ children }) => <span className="chip">{children}</span>;
      const Pill = ({ children }) => <span className="pill">{children}</span>;

      const Section = ({ id, title, children }) => (
        <section id={id} className="card" style={{marginBottom: 16}}>
          <h2>{title}</h2>
          <div>{children}</div>
        </section>
      );

      const Hero = () => (
        <header className="card hero">
          <div className="left">
            <div className="name">Majd Wardeh</div>
            <div className="tagline">Computer Vision & Robotics Engineer — Visual SLAM, Autonomous Systems, Embedded ML</div>
            <div className="meta">
              <span>Frankfurt am Main, Germany</span>
              <span><a href="mailto:majd.wardeh@gmail.com">majd.wardeh@gmail.com</a></span>
              <span><a href="tel:+4917676968529">+49 176 7696 8529</a></span>
              <span><a href="https://www.linkedin.com/in/majd-wardeh-893451b7" target="_blank" rel="noreferrer">LinkedIn</a></span>
            </div>
            <div className="labels">
              <Chip>M.E. Electrical & Computer Engineering — AUB</Chip>
              <Chip>B.E. Control & Automation — 1st in class</Chip>
              <Chip>Autonomous Drone Racing</Chip>
              <Chip>Visual SLAM</Chip>
            </div>
          </div>
          <div className="photo" style={{backgroundImage: `url('cv_photo_1.jpg')`}} aria-label="Profile photo" />
        </header>
      );

      const ExperienceBlock = ({ role, time, place, summary, bullets = [], tags = [] }) => (
        <div className="block">
          <div className="title-line">
            <div>{role}</div>
            <div>{time}</div>
          </div>
          {place && <div className="sub">{place}</div>}
          {summary && <p style={{marginTop: 4}}>{summary}</p>}
          {bullets.length > 0 && (
            <ul>
              {bullets.map((b, i) => <li key={i}>{b}</li>)}
            </ul>
          )}
          {tags.length > 0 && (
            <div className="pills">
              {tags.map((t, i) => <Pill key={i}>{t}</Pill>)}
            </div>
          )}
        </div>
      );

      const ProjectBlock = ({ title, meta, children, links = [] }) => (
        <div className="block">
          <div className="title-line"><div>{title}</div></div>
          {meta && <div className="sub">{meta}</div>}
          {children && <p style={{marginTop: 4}}>{children}</p>}
          {links.length > 0 && (
            <div className="links" style={{marginTop: 4}}>
              {links.map(({ href, label }, i) => (
                <a key={i} href={href} target="_blank" rel="noreferrer">{label}</a>
              ))}
            </div>
          )}
        </div>
      );

      const App = () => (
        <>
          <Hero />
          <main>
            <div>
              <Section id="about" title="About">
                <p>
                  I build vision-based systems that work under real constraints: autonomous parking using surround-view cameras,
                  quadrotors racing through gates at speed, and robots localizing and planning from onboard sensors only. My work combines
                  <strong> deep learning</strong>, <strong> visual SLAM</strong>, <strong> trajectory optimization</strong>, and <strong> embedded deployment</strong>.
                </p>
              </Section>

              <Section id="experience" title="Experience">
                <ExperienceBlock
                  role="Computer Vision Engineer, Visual SLAM"
                  time="Jun 2022 — Present"
                  place="Hyundai MOBIS Parts Europe N.V., Frankfurt"
                  summary="Contributing to Memory Parking Assistant (MPA): robust mapping and localization with surround-view cameras in indoor/outdoor environments."
                  bullets={[
                    'Designed unsupervised keypoint detection networks with custom KPIs (COLMAP-based 3D reconstruction).',
                    'Built automated pipelines to benchmark robustness and quantized models.',
                    'Integrated keypoint detection into a multi-head production network.',
                    'Implemented EKF-based sensor fusion combining multi-camera localization and odometry with uncertainty estimation.',
                    'Contributed C/C++ integration on embedded platforms under real-time constraints.',
                  ]}
                  tags={[ 'Visual SLAM', 'PyTorch', 'C/C++', 'Embedded Linux', 'ROS', 'Docker • Git' ]}
                />

                <ExperienceBlock
                  role="Research Assistant, Vision & Robotics Lab"
                  time="Jan 2019 — May 2022"
                  place="American University of Beirut"
                  summary="Research on autonomous drone racing: vision-based navigation, gate detection, and minimum-time trajectory generation."
                  bullets={[
                    'Supervised learning for gate perception and navigation.',
                    'Minimum-time trajectories via nonlinear optimization, differential flatness & B-splines.',
                    'Deployed deep models on NVIDIA Jetson TX2 for real-time onboard perception.',
                  ]}
                  tags={[ 'Deep Learning', 'TensorFlow', 'CVXPY', 'Nonlinear Optimization', 'ROS' ]}
                />

                <ExperienceBlock
                  role="Teaching & Lab Instructor"
                  time="2017 — 2019"
                  place="AUB • Yarmouk Univ. • Damascus Univ."
                  summary="Led labs in Instrumentation, Electrical & Logic Circuits, and Operating Systems (Linux, shell scripting, processes, semaphores, multithreading)."
                />
              </Section>

              <Section id="projects" title="Selected Projects">
                <ProjectBlock
                  title="Badminton Playing Robot (BSc FYP)"
                  meta="Kinect tracking • Omni-directional robot • C#, C++"
                  links={[{ href: 'https://youtu.be/ECZxJFbRK5Y', label: 'Video' }]}
                >
                  Real-time shuttlecock tracking, trajectory estimation, and robot control.
                </ProjectBlock>

                <ProjectBlock
                  title="Gate Corner Detection for ADR"
                  meta="CNN with Partial Affinity Fields • Python"
                >
                  Deep model for precise racing gate corner localization as part of drone racing stack.
                </ProjectBlock>

                <ProjectBlock
                  title="Vision-based Minimum-Time Quadrotor Trajectories"
                  meta="Nonlinear optimization • SQP • B-splines"
                >
                  Implemented Penin et al. style planner ensuring visibility of gates while minimizing lap time.
                </ProjectBlock>

                <ProjectBlock
                  title="Fast SLAM on Husky Robot"
                  meta="Python • ROS • Gazebo"
                  links={[{ href: 'https://github.com/Majd-Wardeh/Fast_SLAM/tree/main', label: 'Code' }]}
                >
                  Monte Carlo Localization and Fast SLAM with multiprocessing for real-time simulation.
                </ProjectBlock>

                <ProjectBlock
                  title="Tetris Playing Robots (WRO ARC 2017 & 2018)"
                  meta="LabVIEW • Vision • Robotics"
                  links={[
                    { href: 'https://youtu.be/akM8H4mN5KU?t=40', label: 'V1' },
                    { href: 'https://youtu.be/hYsgETGX-HU', label: 'V2' },
                  ]}
                >
                  Omni-directional robots with manipulators and robust part detection. 2nd Syria (2017), 1st Syria (2018), 9th/25 World Finals.
                </ProjectBlock>

                <ProjectBlock
                  title="Mars Rover Robot (EDC 3.0)"
                  meta="C++ • Custom 360° LiDAR"
                  links={[{ href: 'https://www.youtube.com/watch?v=0ADbrZ44sHI', label: 'Video' }]}
                >
                  Autonomous rover with in-house LiDAR; 1st Place + Design Award.
                </ProjectBlock>

                <ProjectBlock
                  title="Fast Gate Detector for Drone Racing"
                  meta="Classical CV • OpenCV"
                  links={[{ href: 'https://youtu.be/DNZrFw6UsgE', label: 'Demo' }]}
                >
                  LED gate detector reaching ~305 FPS on Intel i7.
                </ProjectBlock>

                <ProjectBlock
                  title="Face Recognition with Triplet Loss"
                  meta="Deep Metric Learning"
                >
                  Low-shot face recognition inspired by VGG Face with ~10 images/identity.
                </ProjectBlock>
              </Section>
            </div>

            <div>
              <Section id="thesis" title="Master's Thesis">
                <div className="block">
                  <div className="title-line"><div>Vision-based Autonomous Drone Racing</div></div>
                  <p style={{marginTop: 4}}>
                    End-to-end system for autonomous quadrotor navigation through racing gates using only onboard sensing.
                  </p>
                  <ul>
                    <li><strong>Perception network</strong> for gate detection and 2D corner regression.</li>
                    <li><strong>Policy network</strong> generating Bézier-parameterized 4D trajectory segments.</li>
                  </ul>
                  <p className="note">~90% gate traversal success at speeds up to 5 m/s.</p>
                  <p className="note">Thesis results video: <a href="#" target="_blank" rel="noreferrer">Add YouTube link here</a></p>
                </div>
              </Section>

              <Section id="education" title="Education">
                <div className="block">
                  <div className="title-line"><div>M.E. Electrical & Computer Engineering</div><div>2018 — 2022</div></div>
                  <div className="sub">American University of Beirut</div>
                  <p className="note">Major: Robotics & Machine Intelligence • Minor: Communications & Signal Processing • 89.57 / 100</p>
                </div>
                <div className="block">
                  <div className="title-line"><div>B.E. Control & Automation Engineering</div><div>2012 — 2017</div></div>
                  <div className="sub">Damascus University</div>
                  <p className="note">85.85 / 100 • Ranked 1st in class.</p>
                </div>
              </Section>

              <Section id="awards" title="Awards & Distinctions">
                <ul className="note" style={{listStyle: 'none', paddingLeft: 0}}>
                  <li><strong>Master's Graduate Fellowship</strong>, AUB ECE Dept.</li>
                  <li><strong>Al-Basel Awards for Academic Excellence</strong>, 2014—2016.</li>
                  <li><strong>WRO ARC:</strong> 1st Syria (2018), 9th/25 World Finals.</li>
                  <li><strong>EDC 3.0:</strong> 1st Place & Design Award.</li>
                </ul>
              </Section>

              <Section id="skills" title="Skills">
                <p className="note">
                  <strong>ML & Vision:</strong> Deep Learning, Visual SLAM, 3D Vision, Gate Detection, Tracking<br />
                  <strong>Control & Planning:</strong> Trajectory Optimization, Sensor Fusion (EKF), Robotics<br />
                  <strong>Tools:</strong> PyTorch, TensorFlow, OpenCV, CVXPY, MLflow, ROS<br />
                  <strong>Languages:</strong> Python, C/C++, C#, LabVIEW<br />
                  <strong>Platforms:</strong> NVIDIA Jetson, Embedded Linux, Docker, Git
                </p>
              </Section>

              <Section id="contact" title="Contact">
                <p className="note">
                  Open to roles in Computer Vision, Autonomous Driving, Robotics, and Research Engineering.
                  For collaborations: <a href="mailto:majd.wardeh@gmail.com">majd.wardeh@gmail.com</a>.
                </p>
              </Section>
            </div>
          </main>

          <div className="footer">© <span>{new Date().getFullYear()}</span> Majd Wardeh</div>
        </>
      );

      const root = ReactDOM.createRoot(document.getElementById('root'));
      root.render(<App />);
    </script>
  </body>
  </html>

